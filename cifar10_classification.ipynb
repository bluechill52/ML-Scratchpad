{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba5ae29-b44b-43c2-8030-671ad402b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp39-cp39-linux_x86_64.whl (2267.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m479.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp39-cp39-linux_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp39-cp39-linux_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m821.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Collecting triton==2.0.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m936.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.24.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading https://download.pytorch.org/whl/Pillow-9.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /local/mnt/workspace/Tools/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33m  WARNING: Building wheel for lit failed: [Errno 122] Disk quota exceeded\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for lit\n",
      "Failed to build lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, pillow, numpy, networkx, filelock, triton, torch, torchvision, torchaudio\n",
      "  Running setup.py install for lit ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: lit was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. pip 23.1 will enforce this behaviour change. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25hSuccessfully installed cmake-3.25.0 filelock-3.9.0 lit-15.0.7 mpmath-1.2.1 networkx-3.0 numpy-1.24.1 pillow-9.3.0 sympy-1.11.1 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6e194b-ebc1-4575-ac54-8ef52fe771c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0231c234-0dbf-4050-8af5-0685fc077e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024e60c1-26e8-4568-9dcc-1b16a3b6833c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 25\u001b[0m net \u001b[38;5;241m=\u001b[39m Net()\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f03c9351-5e4e-4b98-99c5-d4939d597c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 1.281\n",
      "[1,    40] loss: 1.334\n",
      "[1,    60] loss: 1.335\n",
      "[1,    80] loss: 1.329\n",
      "[1,   100] loss: 1.326\n",
      "[1,   120] loss: 1.348\n",
      "[1,   140] loss: 1.321\n",
      "[1,   160] loss: 1.328\n",
      "[1,   180] loss: 1.334\n",
      "[1,   200] loss: 1.277\n",
      "[1,   220] loss: 1.321\n",
      "[1,   240] loss: 1.303\n",
      "[1,   260] loss: 1.310\n",
      "[1,   280] loss: 1.284\n",
      "[1,   300] loss: 1.335\n",
      "[1,   320] loss: 1.312\n",
      "[1,   340] loss: 1.289\n",
      "[1,   360] loss: 1.328\n",
      "[1,   380] loss: 1.334\n",
      "Accuracy 52.679996490478516\n",
      "[2,    20] loss: 1.266\n",
      "[2,    40] loss: 1.307\n",
      "[2,    60] loss: 1.300\n",
      "[2,    80] loss: 1.287\n",
      "[2,   100] loss: 1.295\n",
      "[2,   120] loss: 1.316\n",
      "[2,   140] loss: 1.314\n",
      "[2,   160] loss: 1.285\n",
      "[2,   180] loss: 1.261\n",
      "[2,   200] loss: 1.278\n",
      "[2,   220] loss: 1.299\n",
      "[2,   240] loss: 1.316\n",
      "[2,   260] loss: 1.265\n",
      "[2,   280] loss: 1.316\n",
      "[2,   300] loss: 1.326\n",
      "[2,   320] loss: 1.273\n",
      "[2,   340] loss: 1.311\n",
      "[2,   360] loss: 1.290\n",
      "[2,   380] loss: 1.296\n",
      "Accuracy 53.8599967956543\n",
      "[3,    20] loss: 1.259\n",
      "[3,    40] loss: 1.264\n",
      "[3,    60] loss: 1.262\n",
      "[3,    80] loss: 1.283\n",
      "[3,   100] loss: 1.265\n",
      "[3,   120] loss: 1.269\n",
      "[3,   140] loss: 1.286\n",
      "[3,   160] loss: 1.335\n",
      "[3,   180] loss: 1.283\n",
      "[3,   200] loss: 1.232\n",
      "[3,   220] loss: 1.288\n",
      "[3,   240] loss: 1.240\n",
      "[3,   260] loss: 1.330\n",
      "[3,   280] loss: 1.251\n",
      "[3,   300] loss: 1.280\n",
      "[3,   320] loss: 1.253\n",
      "[3,   340] loss: 1.270\n",
      "[3,   360] loss: 1.271\n",
      "[3,   380] loss: 1.268\n",
      "Accuracy 53.84000015258789\n",
      "[4,    20] loss: 1.238\n",
      "[4,    40] loss: 1.253\n",
      "[4,    60] loss: 1.263\n",
      "[4,    80] loss: 1.282\n",
      "[4,   100] loss: 1.245\n",
      "[4,   120] loss: 1.232\n",
      "[4,   140] loss: 1.232\n",
      "[4,   160] loss: 1.274\n",
      "[4,   180] loss: 1.225\n",
      "[4,   200] loss: 1.251\n",
      "[4,   220] loss: 1.231\n",
      "[4,   240] loss: 1.291\n",
      "[4,   260] loss: 1.251\n",
      "[4,   280] loss: 1.244\n",
      "[4,   300] loss: 1.291\n",
      "[4,   320] loss: 1.261\n",
      "[4,   340] loss: 1.255\n",
      "[4,   360] loss: 1.213\n",
      "[4,   380] loss: 1.248\n",
      "Accuracy 55.279998779296875\n",
      "[5,    20] loss: 1.203\n",
      "[5,    40] loss: 1.266\n",
      "[5,    60] loss: 1.222\n",
      "[5,    80] loss: 1.227\n",
      "[5,   100] loss: 1.221\n",
      "[5,   120] loss: 1.201\n",
      "[5,   140] loss: 1.249\n",
      "[5,   160] loss: 1.223\n",
      "[5,   180] loss: 1.207\n",
      "[5,   200] loss: 1.225\n",
      "[5,   220] loss: 1.258\n",
      "[5,   240] loss: 1.240\n",
      "[5,   260] loss: 1.193\n",
      "[5,   280] loss: 1.249\n",
      "[5,   300] loss: 1.230\n",
      "[5,   320] loss: 1.247\n",
      "[5,   340] loss: 1.305\n",
      "[5,   360] loss: 1.243\n",
      "[5,   380] loss: 1.252\n",
      "Accuracy 55.75\n",
      "[6,    20] loss: 1.225\n",
      "[6,    40] loss: 1.206\n",
      "[6,    60] loss: 1.219\n",
      "[6,    80] loss: 1.229\n",
      "[6,   100] loss: 1.247\n",
      "[6,   120] loss: 1.221\n",
      "[6,   140] loss: 1.217\n",
      "[6,   160] loss: 1.183\n",
      "[6,   180] loss: 1.219\n",
      "[6,   200] loss: 1.241\n",
      "[6,   220] loss: 1.226\n",
      "[6,   240] loss: 1.217\n",
      "[6,   260] loss: 1.216\n",
      "[6,   280] loss: 1.196\n",
      "[6,   300] loss: 1.164\n",
      "[6,   320] loss: 1.205\n",
      "[6,   340] loss: 1.228\n",
      "[6,   360] loss: 1.200\n",
      "[6,   380] loss: 1.238\n",
      "Accuracy 55.87999725341797\n",
      "[7,    20] loss: 1.182\n",
      "[7,    40] loss: 1.195\n",
      "[7,    60] loss: 1.224\n",
      "[7,    80] loss: 1.202\n",
      "[7,   100] loss: 1.244\n",
      "[7,   120] loss: 1.219\n",
      "[7,   140] loss: 1.232\n",
      "[7,   160] loss: 1.195\n",
      "[7,   180] loss: 1.172\n",
      "[7,   200] loss: 1.174\n",
      "[7,   220] loss: 1.204\n",
      "[7,   240] loss: 1.203\n",
      "[7,   260] loss: 1.214\n",
      "[7,   280] loss: 1.185\n",
      "[7,   300] loss: 1.191\n",
      "[7,   320] loss: 1.175\n",
      "[7,   340] loss: 1.161\n",
      "[7,   360] loss: 1.202\n",
      "[7,   380] loss: 1.157\n",
      "Accuracy 56.94999694824219\n",
      "[8,    20] loss: 1.189\n",
      "[8,    40] loss: 1.173\n",
      "[8,    60] loss: 1.183\n",
      "[8,    80] loss: 1.186\n",
      "[8,   100] loss: 1.170\n",
      "[8,   120] loss: 1.181\n",
      "[8,   140] loss: 1.159\n",
      "[8,   160] loss: 1.218\n",
      "[8,   180] loss: 1.168\n",
      "[8,   200] loss: 1.197\n",
      "[8,   220] loss: 1.126\n",
      "[8,   240] loss: 1.186\n",
      "[8,   260] loss: 1.204\n",
      "[8,   280] loss: 1.165\n",
      "[8,   300] loss: 1.163\n",
      "[8,   320] loss: 1.183\n",
      "[8,   340] loss: 1.202\n",
      "[8,   360] loss: 1.201\n",
      "[8,   380] loss: 1.158\n",
      "Accuracy 57.41999816894531\n",
      "[9,    20] loss: 1.162\n",
      "[9,    40] loss: 1.187\n",
      "[9,    60] loss: 1.194\n",
      "[9,    80] loss: 1.172\n",
      "[9,   100] loss: 1.179\n",
      "[9,   120] loss: 1.169\n",
      "[9,   140] loss: 1.151\n",
      "[9,   160] loss: 1.152\n",
      "[9,   180] loss: 1.176\n",
      "[9,   200] loss: 1.167\n",
      "[9,   220] loss: 1.184\n",
      "[9,   240] loss: 1.134\n",
      "[9,   260] loss: 1.185\n",
      "[9,   280] loss: 1.158\n",
      "[9,   300] loss: 1.207\n",
      "[9,   320] loss: 1.166\n",
      "[9,   340] loss: 1.153\n",
      "[9,   360] loss: 1.157\n",
      "[9,   380] loss: 1.146\n",
      "Accuracy 56.86000061035156\n",
      "[10,    20] loss: 1.184\n",
      "[10,    40] loss: 1.170\n",
      "[10,    60] loss: 1.156\n",
      "[10,    80] loss: 1.182\n",
      "[10,   100] loss: 1.148\n",
      "[10,   120] loss: 1.141\n",
      "[10,   140] loss: 1.126\n",
      "[10,   160] loss: 1.171\n",
      "[10,   180] loss: 1.144\n",
      "[10,   200] loss: 1.176\n",
      "[10,   220] loss: 1.135\n",
      "[10,   240] loss: 1.146\n",
      "[10,   260] loss: 1.128\n",
      "[10,   280] loss: 1.139\n",
      "[10,   300] loss: 1.146\n",
      "[10,   320] loss: 1.175\n",
      "[10,   340] loss: 1.153\n",
      "[10,   360] loss: 1.127\n",
      "[10,   380] loss: 1.144\n",
      "Accuracy 58.189998626708984\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "            \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        num_examples += labels.size(0)\n",
    "        correct_pred += (predicted_labels == labels).sum()\n",
    "    return correct_pred.float() / num_examples * 100\n",
    "    \n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # Compute accuracy after each epoch\n",
    "    net.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        accuracy = compute_accuracy(net, testloader, device)\n",
    "        print('Accuracy {}'.format(accuracy))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80fda5db-0f35-42c5-92f4-44188cddc8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataiter = iter(te"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
